# ğŸ“ˆ å¦‚ä½•ç”¨æ·±åº¦å¼ºåŒ–å­¦ä¹ è‡ªåŠ¨ç‚’è‚¡

## âœ¨å‰è¨€
æœ¬ç­–ç•¥ä¸»è¦å‚è€ƒhttps://github.com/wangshub/RL-Stockï¼Œåœ¨åŸç­–ç•¥åŸºç¡€ä¸Šä¸»è¦åšäº†å¦‚ä¸‹ä¼˜åŒ–ï¼š
- å‡çº§æœ€æ–°çš„åŸºäºpytorchçš„å¼ºåŒ–å­¦ä¹ å·¥å…·åº“stable-baselines3
- è§£å†³å¼ºåŒ–å­¦ä¹ ç¯å¢ƒä¸­Boxç²¾åº¦è­¦å‘Š
- è§£å†³å¼ºåŒ–å­¦ä¹ ç¯å¢ƒä¸­self.cost_basisåˆ†æ¯é™¤0è­¦å‘Š
- é‡æ„ä¸»å‡½æ•°æµç¨‹

## ğŸ’¡ åˆè¡·

æœ€è¿‘ä¸€æ®µæ—¶é—´ï¼Œå—åˆ°æ–°å† ç–«æƒ…çš„å½±å“ï¼Œè‚¡å¸‚æ¥è¿ä¸‹è·Œï¼Œä½œä¸ºä¸€æ£µå°ç™½èœå…¼å°éŸ­èœï¼Œç«Ÿç„¶äº§ç”Ÿäº†æŠ„åº•çš„å¤§èƒ†æƒ³æ³•ï¼Œæ‹¿å‡ºä»…å­˜çš„ä¸€ç‚¹ç§æˆ¿é’±æ¢­å“ˆäº†ä¸€æŠŠã€‚

ç¬¬äºŒå¤©ï¼Œæš´è·Œï¼Œä¿ºåŠ ä»“

ç¬¬ä¸‰å¤©ï¼Œåˆè·Œï¼Œä¿ºåŠ ä»“

ç¬¬ä¸‰å¤©ï¼Œåˆè·Œï¼Œä¿ºåˆåŠ ä»“...

![è‚¡ç¥¨äº¤æ˜“ç‚¹](./img/2020-03-27-10-45-59.png)

ä¸€ç•ªé”™è¯¯æ“ä½œåï¼Œç»“æœæƒ¨ä¸å¿ç¹ï¼Œç¬¬ä¸€æ¬¡ä¹°è‚¡ç¥¨å°±è¢«è‚¡å¸‚ä¸€æ®µæš´æ‰“ï¼Œå—åˆ°äº†åª³å¦‡æ— æƒ…çš„å˜²è®½ã€‚ç—›å®šæ€ç—›ï¼Œä¿ºå†³å®šæ¢ä¸€ä¸ªæ€è·¯ï¼š**å¦‚ä½•ç”¨æ·±åº¦å¼ºåŒ–å­¦ä¹ æ¥è‡ªåŠ¨æ¨¡æ‹Ÿç‚’è‚¡ï¼Ÿ** å®éªŒéªŒè¯ä¸€ä¸‹èƒ½å¦è·å¾—æ”¶ç›Šã€‚
    
## ğŸ“– ç›‘ç£å­¦ä¹ ä¸å¼ºåŒ–å­¦ä¹ çš„åŒºåˆ«

ç›‘ç£å­¦ä¹ ï¼ˆå¦‚ LSTMï¼‰å¯ä»¥æ ¹æ®å„ç§å†å²æ•°æ®æ¥é¢„æµ‹æœªæ¥çš„è‚¡ç¥¨çš„ä»·æ ¼ï¼Œåˆ¤æ–­è‚¡ç¥¨æ˜¯æ¶¨è¿˜æ˜¯è·Œï¼Œå¸®åŠ©äººåšå†³ç­–ã€‚

![ç›‘ç£å­¦ä¹ ](./img/2020-03-25-18-55-13.png)

è€Œå¼ºåŒ–å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„å¦ä¸€ä¸ªåˆ†æ”¯ï¼Œåœ¨å†³ç­–çš„æ—¶å€™é‡‡å–åˆé€‚çš„è¡ŒåŠ¨ (Action) ä½¿æœ€åçš„å¥–åŠ±æœ€å¤§åŒ–ã€‚ä¸ç›‘ç£å­¦ä¹ é¢„æµ‹æœªæ¥çš„æ•°å€¼ä¸åŒï¼Œå¼ºåŒ–å­¦ä¹ æ ¹æ®è¾“å…¥çš„çŠ¶æ€ï¼ˆå¦‚å½“æ—¥å¼€ç›˜ä»·ã€æ”¶ç›˜ä»·ç­‰ï¼‰ï¼Œè¾“å‡ºç³»åˆ—åŠ¨ä½œï¼ˆä¾‹å¦‚ï¼šä¹°è¿›ã€æŒæœ‰ã€å–å‡ºï¼‰ï¼Œä½¿å¾—æœ€åçš„æ”¶ç›Šæœ€å¤§åŒ–ï¼Œå®ç°è‡ªåŠ¨äº¤æ˜“ã€‚

![å¼ºåŒ–å­¦ä¹ ](./img/2020-03-25-18-19-03.png)

## ğŸ¤– OpenAI Gym è‚¡ç¥¨äº¤æ˜“ç¯å¢ƒ

### è§‚æµ‹ Observation

ç­–ç•¥ç½‘ç»œè§‚æµ‹çš„å°±æ˜¯ä¸€åªè‚¡ç¥¨çš„å„é¡¹å‚æ•°ï¼Œæ¯”å¦‚å¼€ç›˜ä»·ã€æ”¶ç›˜ä»·ã€æˆäº¤æ•°é‡ç­‰ã€‚éƒ¨åˆ†æ•°å€¼ä¼šæ˜¯ä¸€ä¸ªå¾ˆå¤§çš„æ•°å€¼ï¼Œæ¯”å¦‚æˆäº¤é‡‘é¢æˆ–è€…æˆäº¤é‡ï¼Œæœ‰å¯èƒ½ç™¾ä¸‡ã€åƒä¸‡ä¹ƒè‡³æ›´å¤§ï¼Œä¸ºäº†è®­ç»ƒæ—¶ç½‘ç»œæ”¶æ•›ï¼Œè§‚æµ‹çš„çŠ¶æ€æ•°æ®è¾“å…¥æ—¶ï¼Œå¿…é¡»è¦è¿›è¡Œå½’ä¸€åŒ–ï¼Œå˜æ¢åˆ° `[-1, 1]` çš„åŒºé—´å†…ã€‚

|å‚æ•°åç§°|å‚æ•°æè¿°|è¯´æ˜|
|---|---|---|
|date|äº¤æ˜“æ‰€è¡Œæƒ…æ—¥æœŸ|æ ¼å¼ï¼šYYYY-MM-DD|
|code|è¯åˆ¸ä»£ç |æ ¼å¼ï¼šsh.600000ã€‚shï¼šä¸Šæµ·ï¼Œszï¼šæ·±åœ³|
|open|ä»Šå¼€ç›˜ä»·æ ¼|ç²¾åº¦ï¼šå°æ•°ç‚¹å4ä½ï¼›å•ä½ï¼šäººæ°‘å¸å…ƒ|
|high|æœ€é«˜ä»·|ç²¾åº¦ï¼šå°æ•°ç‚¹å4ä½ï¼›å•ä½ï¼šäººæ°‘å¸å…ƒ|
|low|æœ€ä½ä»·|ç²¾åº¦ï¼šå°æ•°ç‚¹å4ä½ï¼›å•ä½ï¼šäººæ°‘å¸å…ƒ|
|close|ä»Šæ”¶ç›˜ä»·|ç²¾åº¦ï¼šå°æ•°ç‚¹å4ä½ï¼›å•ä½ï¼šäººæ°‘å¸å…ƒ|
|preclose|æ˜¨æ—¥æ”¶ç›˜ä»·|ç²¾åº¦ï¼šå°æ•°ç‚¹å4ä½ï¼›å•ä½ï¼šäººæ°‘å¸å…ƒ|
|volume|æˆäº¤æ•°é‡|å•ä½ï¼šè‚¡|
|amount|æˆäº¤é‡‘é¢|ç²¾åº¦ï¼šå°æ•°ç‚¹å4ä½ï¼›å•ä½ï¼šäººæ°‘å¸å…ƒ|
|adjustflag|å¤æƒçŠ¶æ€|ä¸å¤æƒã€å‰å¤æƒã€åå¤æƒ|
|turn|æ¢æ‰‹ç‡|ç²¾åº¦ï¼šå°æ•°ç‚¹å6ä½ï¼›å•ä½ï¼š%|
|tradestatus|äº¤æ˜“çŠ¶æ€|1ï¼šæ­£å¸¸äº¤æ˜“ 0ï¼šåœç‰Œ|
|pctChg|æ¶¨è·Œå¹…ï¼ˆç™¾åˆ†æ¯”ï¼‰|ç²¾åº¦ï¼šå°æ•°ç‚¹å6ä½|
|peTTM|æ»šåŠ¨å¸‚ç›ˆç‡|ç²¾åº¦ï¼šå°æ•°ç‚¹å6ä½|
|psTTM|æ»šåŠ¨å¸‚é”€ç‡|ç²¾åº¦ï¼šå°æ•°ç‚¹å6ä½|
|pcfNcfTTM|æ»šåŠ¨å¸‚ç°ç‡|ç²¾åº¦ï¼šå°æ•°ç‚¹å6ä½|
|pbMRQ|å¸‚å‡€ç‡|ç²¾åº¦ï¼šå°æ•°ç‚¹å6ä½|

### åŠ¨ä½œ Action

å‡è®¾äº¤æ˜“å…±æœ‰**ä¹°å…¥**ã€**å–å‡º**å’Œ**ä¿æŒ** 3 ç§æ“ä½œï¼Œå®šä¹‰åŠ¨ä½œ(`action`)ä¸ºé•¿åº¦ä¸º 2 çš„æ•°ç»„

- `action[0]` ä¸ºæ“ä½œç±»å‹ï¼›
- `action[1]` è¡¨ç¤ºä¹°å…¥æˆ–å–å‡ºç™¾åˆ†æ¯”ï¼›

| åŠ¨ä½œç±»å‹ `action[0]` | è¯´æ˜ |
|---|---|
| 1 | ä¹°å…¥ `action[1]`|
| 2 | å–å‡º `action[1]`|
| 3 | ä¿æŒ |

æ³¨æ„ï¼Œå½“åŠ¨ä½œç±»å‹ `action[0] = 3` æ—¶ï¼Œè¡¨ç¤ºä¸ä¹°ä¹Ÿä¸æŠ›å”®è‚¡ç¥¨ï¼Œæ­¤æ—¶ `action[1]` çš„å€¼æ— å®é™…æ„ä¹‰ï¼Œç½‘ç»œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼ŒAgent ä¼šæ…¢æ…¢å­¦ä¹ åˆ°è¿™ä¸€ä¿¡æ¯ã€‚

### å¥–åŠ± Reward

å¥–åŠ±å‡½æ•°çš„è®¾è®¡ï¼Œå¯¹å¼ºåŒ–å­¦ä¹ çš„ç›®æ ‡è‡³å…³é‡è¦ã€‚åœ¨è‚¡ç¥¨äº¤æ˜“çš„ç¯å¢ƒä¸‹ï¼Œæœ€åº”è¯¥å…³å¿ƒçš„å°±æ˜¯å½“å‰çš„ç›ˆåˆ©æƒ…å†µï¼Œæ•…ç”¨å½“å‰çš„åˆ©æ¶¦ä½œä¸ºå¥–åŠ±å‡½æ•°ã€‚å³`å½“å‰æœ¬é‡‘ + è‚¡ç¥¨ä»·å€¼ - åˆå§‹æœ¬é‡‘ = åˆ©æ¶¦`ã€‚

```python
# profits
reward = self.net_worth - INITIAL_ACCOUNT_BALANCE
reward = 1 if reward > 0 else reward = -100
```

ä¸ºäº†ä½¿ç½‘ç»œæ›´å¿«å­¦ä¹ åˆ°ç›ˆåˆ©çš„ç­–ç•¥ï¼Œå½“åˆ©æ¶¦ä¸ºè´Ÿå€¼æ—¶ï¼Œç»™äºˆç½‘ç»œä¸€ä¸ªè¾ƒå¤§çš„æƒ©ç½š (`-100`)ã€‚

### ç­–ç•¥æ¢¯åº¦

å› ä¸ºåŠ¨ä½œè¾“å‡ºçš„æ•°å€¼æ˜¯è¿ç»­ï¼Œå› æ­¤ä½¿ç”¨åŸºäºç­–ç•¥æ¢¯åº¦çš„ä¼˜åŒ–ç®—æ³•ï¼Œå…¶ä¸­æ¯”è¾ƒçŸ¥åçš„æ˜¯ [PPO ç®—æ³•](https://arxiv.org/abs/1707.06347)ï¼ŒOpenAI å’Œè®¸å¤šæ–‡çŒ®å·²æŠŠ PPO ä½œä¸ºå¼ºåŒ–å­¦ä¹ ç ”ç©¶ä¸­é¦–é€‰çš„ç®—æ³•ã€‚PPO ä¼˜åŒ–ç®—æ³• Python å®ç°å‚è€ƒ [stable-baselines](https://stable-baselines.readthedocs.io/en/master/modules/ppo2.html)ã€‚

## ğŸ•µï¸â€â™€ï¸ æ¨¡æ‹Ÿå®éªŒ

### ç¯å¢ƒå®‰è£…

1. åˆ›å»ºcondaç¯å¢ƒå¹¶å®‰è£…éœ€è¦çš„åº“
    ```
    # è™šæ‹Ÿç¯å¢ƒ
    conda create -n rl_stock python=3.8
    conda activate rl_stock
    # å®‰è£…åº“ä¾èµ–
    pip install -r requirements.txt
    ```
    
    å¯ä»¥çœ‹åˆ°éœ€è¦çš„åº“å¦‚ä¸‹ï¼š
    ```
    baostock==0.8.8  
    stable-baselines3==1.6.2
    gym==0.21.0
    torch==1.13.1
    tensorboard==2.11.0
    ```
   
    * æ•°æ®æºï¼šè‚¡ç¥¨è¯åˆ¸æ•°æ®é›†æ¥è‡ªäº [baostock](http://baostock.com/baostock/index.php/%E9%A6%96%E9%A1%B5)ï¼Œ
      ä¸€ä¸ªå…è´¹ã€å¼€æºçš„è¯åˆ¸æ•°æ®å¹³å°ï¼Œæä¾› Python APIã€‚
      ```bash
        >> pip install baostock -i https://pypi.tuna.tsinghua.edu.cn/simple/ --trusted-host pypi.tuna.tsinghua.edu.cn
      ```
    * å¼ºåŒ–å­¦ä¹ åº“ï¼šé‡‡ç”¨æœ€æ–°çš„stable-baselines3ï¼Œå…¶ä¾èµ–pytorch 1.11ä»¥ä¸Šç‰ˆæœ¬
    * å¼ºåŒ–å­¦ä¹ ç¯å¢ƒï¼šåŸºäºgymæ„å»ºï¼Œåœ¨quant_brain/rl/envs/StockTradingEnv0.py,
      åŸºäºå¼€æºä»£ç https://github.com/wangshub/RL-Stockå’Œ
      https://github.com/notadamking/Stock-Trading-Environment
      
2. å¦‚ä½•è¿è¡Œï¼š
   ä»£ç ä¼šè‡ªåŠ¨åœ¨dataç›®å½•ä¸‹ä¸‹è½½è®­ç»ƒå’Œæµ‹è¯•æ•°æ®ï¼Œåˆ†åˆ«æ¨¡æ‹Ÿå•ä¸ªè‚¡ç¥¨å’Œå¤šä¸ªè‚¡ç¥¨äº¤æ˜“ã€‚
   ```bash
   python main.py
   ```

### è‚¡ç¥¨æ•°æ®è·å–

è‚¡ç¥¨è¯åˆ¸æ•°æ®é›†æ¥è‡ªäº [baostock](http://baostock.com/baostock/index.php/%E9%A6%96%E9%A1%B5)ï¼Œä¸€ä¸ªå…è´¹ã€å¼€æºçš„è¯åˆ¸æ•°æ®å¹³å°ï¼Œæä¾› Python APIã€‚

```bash
>> pip install baostock -i https://pypi.tuna.tsinghua.edu.cn/simple/ --trusted-host pypi.tuna.tsinghua.edu.cn
```

æ•°æ®è·å–ä»£ç quant_brain/data_io/baostock/get_stock_data.pyï¼Œå•ç‹¬è¿è¡Œå¯æ‰§è¡Œå¦‚ä¸‹å‘½ä»¤ï¼š

```python
>> python get_stock_data.py
```

æ•°æ®ä¸‹è½½å¤§çº¦éœ€è¦20åˆ†é’Ÿå·¦å³ã€‚

å°†è¿‡å» 20 å¤šå¹´çš„è‚¡ç¥¨æ•°æ®åˆ’åˆ†ä¸ºè®­ç»ƒé›†ï¼Œå’Œæœ«å°¾ 1 ä¸ªæœˆæ•°æ®ä½œä¸ºæµ‹è¯•é›†ï¼Œæ¥éªŒè¯å¼ºåŒ–å­¦ä¹ ç­–ç•¥çš„æœ‰æ•ˆæ€§ã€‚åˆ’åˆ†å¦‚ä¸‹

| `1990-01-01` ~ `2019-11-29` | `2019-12-01` ~ `2019-12-31` |
|---|---|
| è®­ç»ƒé›† | æµ‹è¯•é›† |

### éªŒè¯ç»“æœ

**å•åªè‚¡ç¥¨**

- åˆå§‹æœ¬é‡‘ `10000`
- è‚¡ç¥¨ä»£ç ï¼š`sh.600036`(æ‹›å•†é“¶è¡Œ)
- è®­ç»ƒé›†ï¼š `stockdata/train/sh.600036.æ‹›å•†é“¶è¡Œ.csv`
- æµ‹è¯•é›†ï¼š `stockdata/test/sh.600036.æ‹›å•†é“¶è¡Œ.csv`
- æ¨¡æ‹Ÿæ“ä½œ `20` å¤©ï¼Œæœ€ç»ˆç›ˆåˆ©çº¦ `400`

![å•æ”¯è‚¡ç¥¨æ”¶ç›Š](./img/sh.600036.png)

**å¤šæ”¯è‚¡ç¥¨**

é€‰å– `1002` åªè‚¡ç¥¨ï¼Œè¿›è¡Œè®­ç»ƒï¼Œå…±è®¡

- ç›ˆåˆ©ï¼š `44.5%`
- ä¸äºä¸èµšï¼š `46.5%`
- äºæŸï¼š`9.0%`

![å¤šæ”¯è‚¡ç¥¨æ”¶ç›Š](./img/pie.png)

![å¤šæ”¯è‚¡ç¥¨æ”¶ç›Š](./img/hist.png)

## ğŸœä»£ç è§£è¯»

### 1.æ•°æ®è·å–ï¼šquant_brain/data_io/baostock/get_stock_data.py
1. åˆå§‹åŒ–
    ```python
    # ç™»å½• baostock
    bs.login()
    # è®¾ç½®ä¸‹è½½å­—æ®µ
    self.fields = "date,code,open,high,low,close,volume,amount," \
                          "adjustflag,turn,tradestatus,pctChg,peTTM," \
                          "pbMRQ,psTTM,pcfNcfTTM,isST"
    ```

2. è·å–è‚¡ç¥¨åˆ—è¡¨
   æŒ‰ç…§ç»“æŸæŸ¥è¯¢æ—¥æœŸï¼Œè·å–è‚¡ç¥¨
   ```python
   stock_rs = bs.query_all_stock(date)
   stock_df = stock_rs.get_data()
   ```

3. æ ¹æ®è‚¡ç¥¨åˆ—è¡¨ä¸‹è½½è‚¡ç¥¨æ•°æ®
    ä¼šä¸‹è½½æŒ‡æ•°ä»¥åŠå¤§çº¦4000+è‚¡ç¥¨ä¿¡æ¯ï¼ŒæŒ‰ç…§è‚¡ç¥¨åˆ—è¡¨éå†ä¸‹è½½
    ``` python
        # éå†ä¸‹è½½
        for index, row in stock_df.iterrows():
            print(f'processing {row["code"]} {row["code_name"]}')
            # ä¸‹è½½è‚¡ç¥¨æ•°æ®
            df_code = bs.query_history_k_data_plus(row["code"], self.fields,
                                                   start_date=self.date_start,
                                                   end_date=self.date_end).get_data()
            # ä¸€æ”¯è‚¡ç¥¨ä¿å­˜æˆä¸€ä¸ªcsvæ–‡ä»¶
            df_code.to_csv(f'{self.output_dir}/{row["code"]}.{row["code_name"]}.csv', index=False)
        bs.logout()  # é€€å‡ºbaostock

    ```

### 2. è‚¡ç¥¨äº¤æ˜“ç¯å¢ƒ
ä»£ç ä½äºquant_brain/rl/envs/StockTradingEnv0.pyï¼ŒåŸºäºgymåº“æ„å»º

1. è·å–è§‚æµ‹æ•°æ®
   è¯»å–è‚¡ç¥¨çš„csvè½¬æ¢æˆpandasçš„dataframeæ ¼å¼ï¼Œæ¯ä¸€æ¬¡è·å–ä¸€å¤©çš„è§‚æµ‹å€¼ï¼Œ
   å³éå†æ¯æ—¥çš„è‚¡ç¥¨è¡Œæƒ…æ•°æ®ï¼Œå…¶ä¸­å¯¹è‚¡ç¥¨æ•°æ®è¿›è¡Œäº†å½’ä¸€åŒ–å¤„ç†

    ```python
        def _next_observation(self):
            obs = np.array([
                self.df.loc[self.current_step, 'open'] / MAX_SHARE_PRICE,
                self.df.loc[self.current_step, 'high'] / MAX_SHARE_PRICE,
                self.df.loc[self.current_step, 'low'] / MAX_SHARE_PRICE,
                self.df.loc[self.current_step, 'close'] / MAX_SHARE_PRICE,
                self.df.loc[self.current_step, 'volume'] / MAX_VOLUME,
                self.df.loc[self.current_step, 'amount'] / MAX_AMOUNT,
                self.df.loc[self.current_step, 'adjustflag'] / 10,
                self.df.loc[self.current_step, 'tradestatus'] / 1,
                self.df.loc[self.current_step, 'pctChg'] / 100,
                self.df.loc[self.current_step, 'peTTM'] / 1e4,
                self.df.loc[self.current_step, 'pbMRQ'] / 100,
                self.df.loc[self.current_step, 'psTTM'] / 100,
                self.df.loc[self.current_step, 'pctChg'] / 1e3,
                self.balance / MAX_ACCOUNT_BALANCE,
                self.max_net_worth / MAX_ACCOUNT_BALANCE,
                self.shares_held / MAX_NUM_SHARES,
                self.cost_basis / MAX_SHARE_PRICE,
                self.total_shares_sold / MAX_NUM_SHARES,
                self.total_sales_value / (MAX_NUM_SHARES * MAX_SHARE_PRICE),
            ])
            return obs
    ```

2. æ‰§è¡Œçš„åŠ¨ä½œ
    - è‚¡ç¥¨å½“æ—¥å€¼ï¼Œé‡‡ç”¨å¼€ç›˜å’Œæ”¶ç›˜ä»·ä¹‹é—´çš„éšæœºæ•°ä»£æ›¿
    - 0ä¸ºä¹°å…¥ï¼Œ1ä¸ºå–å‡º
    - è®¡ç®—æœ€å¤§æ”¶ç›Š
    
    ```python
        def _take_action(self, action):
            # Set the current price to a random price within the time step
            current_price = random.uniform(
                self.df.loc[self.current_step, "open"], self.df.loc[self.current_step, "close"])
    
            action_type = action[0]
            amount = action[1]
    
            if action_type < 1:
                # Buy amount % of balance in shares
                total_possible = int(self.balance / current_price)
                shares_bought = int(total_possible * amount)  # todo: it might exceed balance?
                prev_cost = self.cost_basis * self.shares_held
                additional_cost = shares_bought * current_price
    
                self.balance -= additional_cost
                if (self.shares_held + shares_bought) != 0:
                    self.cost_basis = (
                        prev_cost + additional_cost) / (self.shares_held + shares_bought)
                self.shares_held += shares_bought
    
            elif action_type < 2:
                # Sell amount % of shares held
                shares_sold = int(self.shares_held * amount)
                self.balance += shares_sold * current_price
                self.shares_held -= shares_sold
                self.total_shares_sold += shares_sold
                self.total_sales_value += shares_sold * current_price
    
            self.net_worth = self.balance + self.shares_held * current_price
    
            if self.net_worth > self.max_net_worth:
                self.max_net_worth = self.net_worth
    
            if self.shares_held == 0:
            self.cost_basis = 0
    ```

3. å¥–åŠ±å€¼è®¡ç®—
    æ ¹æ®æ‰§è¡ŒåŠ¨ä½œå¾—åˆ°çš„æ”¶ç›Šï¼Œè®¡ç®—å¥–åŠ±å€¼
    ```python
    def step(self, action):
        # Execute one time step within the environment
        self._take_action(action)
        done = False

        self.current_step += 1

        if self.current_step > len(self.df.loc[:, 'open'].values) - 1:
            self.current_step = 0  # loop training
            # done = True

        delay_modifier = (self.current_step / MAX_STEPS)

        # profits
        reward = self.net_worth - self.init_balance
        reward = 1 if reward > 0 else -100

        if self.net_worth <= 0:
            done = True

        obs = self._next_observation()

        return obs, reward, done, {}
    ```

### 3. ä¸»å‡½æ•°
ä¸»å‡½æ•°ä¸­ä¸»è¦ä½¿ç”¨äº†stable-baselines3ï¼Œç±»ä¼¼sklearnçš„å¼ºåŒ–å­¦ä¹ åº“ï¼ŒåŸºäºpytorch 1.11ä»¥ä¸Šç‰ˆæœ¬ã€‚
æ„å»ºè®­ç»ƒå’Œæµ‹è¯•æµç¨‹å¦‚ä¸‹ï¼š
    ````python
    class ProtoRLSb3:
        def __init__(self, init_account_balance):
            self.init_account_balance = init_account_balance
            self._model = None
    
        def train(self, stock_file):
            log.info('Start Training ...')
            df = pd.read_csv(stock_file)
            df = df.sort_values('date')
    
            # The algorithms require a vectorized environment to run
            env = DummyVecEnv([lambda: StockTradingEnv(df, self.init_account_balance)])
    
            self._model = PPO(MlpPolicy, env, verbose=0, tensorboard_log='./log')
            self._model.learn(total_timesteps=int(1e4))
    
        def test(self, stock_file):
            day_profits = []
    
            df = pd.read_csv(stock_file)
            df = df.sort_values('date')
    
            env = DummyVecEnv([lambda: StockTradingEnv(df, self.init_account_balance)])
            obs = env.reset()
            for i in range(len(df) - 1):
                action, _states = self._model.predict(obs)
                obs, rewards, done, info = env.step(action)
                profit = env.render()
                day_profits.append(profit)
                if done:
                    break
            return day_profits
    ```
`
## ğŸ‘» æœ€å

- æœ¬ç­–ç•¥æ˜¯ä¸€ä¸ªæœ€åŸºç¡€çš„å¼ºåŒ–å­¦ä¹ åŸå‹ï¼Œæ„åœ¨è®©è¯»è€…å¿«é€Ÿç†Ÿæ‚‰å’Œå­¦ä¹ å…¶åŸºæœ¬ç»“æ„å’Œæ„æˆï¼Œè®¸å¤šåœ°æ–¹å¹¶ä¸å®Œå–„
- è‚¡ç¥¨ Gym ç¯å¢ƒä¸»è¦å‚è€ƒ [Stock-Trading-Environment](https://github.com/notadamking/Stock-Trading-Environment)ï¼Œå¯¹è§‚æµ‹çŠ¶æ€ã€å¥–åŠ±å‡½æ•°å’Œè®­ç»ƒé›†åšäº†ä¿®æ”¹ã€‚
- æœ¬ä»£ç éš¾å…å­˜åœ¨é”™è¯¯ï¼Œæ¬¢è¿æŒ‡æ­£ï¼
- æ•°æ®å’Œæ–¹æ³•çš†æ¥æºäºç½‘ç»œï¼Œæ— æ³•ä¿è¯æœ‰æ•ˆæ€§ï¼Œ**Just For Fun**ï¼


## ğŸ“š å‚è€ƒèµ„æ–™

- å¼ºåŒ–å­¦ä¹ ç‚’è‚¡ï¼šhttps://github.com/wangshub/RL-Stock
- Y. Deng, F. Bao, Y. Kong, Z. Ren and Q. Dai, "Deep Direct Reinforcement Learning for Financial Signal Representation and Trading," in IEEE Transactions on Neural Networks and Learning Systems, vol. 28, no. 3, pp. 653-664, March 2017.
- [Yuqin Dai, Chris Wang, Iris Wang, Yilun Xu, "Reinforcement Learning for FX trading"](http://stanford.edu/class/msande448/2019/Final_reports/gr2.pdf)
- Chien Yi Huang. Financial trading as a game: A deep reinforcement learning approach. arXiv preprint arXiv:1807.02787, 2018.
- [Create custom gym environments from scratch â€” A stock market example](https://towardsdatascience.com/creating-a-custom-openai-gym-environment-for-stock-trading-be532be3910e)
- [notadamking/Stock-Trading-Environment](https://github.com/notadamking/Stock-Trading-Environment)
- [Welcome to Stable Baselines docs! - RL Baselines Made Easy](https://stable-baselines.readthedocs.io/en/master)
